# -*- coding: utf-8 -*-
"""indiaAI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aKCqkIRrtlFFgbqHvz2XRd02mLSg5ZYs
"""

import pandas as pd
import string
import re
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from sklearn.pipeline import Pipeline
import joblib
import matplotlib.pyplot as plt
import seaborn as sns

# Step 1: Load Dataset
file_path = 'test.csv'
data = pd.read_csv(file_path)

# Step 2: Handle Missing Values
data['crimeaditionalinfo'] = data['crimeaditionalinfo'].fillna('')
data['sub_category'] = data['sub_category'].fillna('Unknown')

# Step 3: Text Normalization
def clean_text(text):
    text = text.lower()
    text = re.sub(f"[{string.punctuation}]", "", text)  # Remove punctuation
    text = re.sub(r'\d+', '', text)  # Remove numbers
    return text

data['cleaned_text'] = data['crimeaditionalinfo'].apply(clean_text)

# Step 4: Split Data
X = data['cleaned_text']  # Raw text data for vectorization
y = data['sub_category']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 5: Hyperparameter Tuning using Pipeline
param_grid = {
    'vectorizer__max_features': [1000, 5000, 10000],
    'vectorizer__ngram_range': [(1, 1), (1, 2)],
    'model__alpha': [0.1, 1.0, 10.0]
}

pipeline = Pipeline([
    ('vectorizer', TfidfVectorizer(stop_words='english')),
    ('model', MultinomialNB())
])

grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', verbose=1)
grid_search.fit(X_train, y_train)

print("Best Parameters:", grid_search.best_params_)
model = grid_search.best_estimator_

# Step 6: Evaluation
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")
print(f"F1 Score: {f1}")

# Confusion Matrix Visualization
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(12, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_)
plt.title("Confusion Matrix")
plt.ylabel("Actual")
plt.xlabel("Predicted")
plt.show()